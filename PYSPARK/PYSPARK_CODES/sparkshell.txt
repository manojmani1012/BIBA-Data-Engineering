spark-shell 
scala> val data =sc.textFile("file path.txt")
sc-sparkcontext

scala>val num = Array(1,2,3,4,5,6,7)
scala> val New=sc.parallelize(num)

scala>New.count()

scala>New.collect()

scala>data.take(5)

scala> data.saveAsTextFile("output")

scala>val data = data.filter(line => line.contains("no"))

scala>data.filter(line => line.contains("DataFlair")).count()

scala>data.partitions.length

scala>
scala>

